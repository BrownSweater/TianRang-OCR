# 车牌识别服务部署文档

## 一、服务参数配置

部署时同时支持命令行及JSON文件进行参数配置。

**一般部署时仅需要修改`device_id`**，服务参数详情：

| 参数名          | 类型及默认值              | 说明                                                         |
| --------------- | ------------------------- | ------------------------------------------------------------ |
| host            | str: '0.0.0.0'            | 主机名                                                       |
| port            | int: 8080                 | 端口                                                         |
| device_id       | int: None                 | 设置为None则代表使用CPU；若要使用GPU则设置相应的gpu id，即0代表使用0号显卡。 |
| det_model_path  | str: 'weights/det.pth'    | 检测模型的路径                                               |
| det_thre        | float: 0.7                | 检测模型的box阈值                                            |
| det_short_size  | int: 416                  | 检测模型输入图片的短边大小，尽量设置为32的倍数               |
| rec_model_path  | str: 'weights/recl.pth'   | 识别模型的路径                                               |
| rec_crop_ratio  | float: 1.05               | 裁剪检测到的box时向周围外扩或收缩的比例                      |
| file_record     | bool: false               | 若设置为true，会将识别结果保存在output/result/result_{year}-{month}-{day}文件中，以天进行划分 |
| log_dir         | str: 'output/log/lpr.log' | 服务日志的输出文件                                           |
| debug           | bool: false               | 开启debug模式，会在debug/draw_img和debug/org_img目录下分别保存识别结果的图片（JPG）和原始图片（PNG） |
| use_hyperlpr    | bool: false               | 使用HyperLPR作为识别模型，若设置为true，则rec_model_path失效 |
| use_config_json | bool: false               | 使用'flask_utils/config.json'作为配置参数，若设置为true，命令行参数失效 |

### 1、使用命令行进行参数配置

所有的bool类型的值在命令行中的action都是store_true，即需要配置debug模式，在末尾加上`--debug`

- 使用0号显卡进行部署并且保存识别结果

`nvidia-docker run -it -p ${外部端口}:8080 -v ${日志文件及识别结果文件}:/tianrang-ocr/output ${image} python /tianrang-ocr/app.py --device_id 0 --file_record`

- 使用cpu进行部署并且保存识别结果

`nvidia-docker run -it -p ${外部端口}:8080 -v ${日志文件及识别结果文件}:/tianrang-ocr/output ${image} python /tianrang-ocr/app.py  --file_record`

- 使用cpu进行部署，保存识别结果，使用HyperLPR作为识别模型

`nvidia-docker run -it -p ${外部端口}:8080 -v ${日志文件及识别结果文件}:/tianrang-ocr/output ${image} python /tianrang-ocr/app.py  --file_record --use_hyperlpr`



### 2、使用JSON文件进行参数配置

读取flask_utils/config.json作为参数配置文件，需要将外部json挂载到/tianrang-ocr/flask_utils/config.json

`nvidia-docker run -it -p ${外部端口}:8080 -v ${日志文件及识别结果文件}:/tianrang-ocr/output ${image} -v ${服务配置文件}:/tianrang-ocr/flask_utils/config.json python /tianrang-ocr/app.py --use_config_json`

```json
{
    "debug": false,
    "det_model_path": "'weights/det.pth'",
    "det_short_size": 416,
    "det_thre": 0.7,
    "device_id": null,
    "file_record": true,
    "host": "0.0.0.0",
    "log_dir": "output/log/lpr.log",
    "port": 8080,
    "rec_crop_ratio": 1.05,
    "rec_model_path": "'weights/rec.pth'",
    "use_hyperlpr": false
}
```



## 二、文件挂载

| 说明                                           | 容器内部路径                          |
| ---------------------------------------------- | ------------------------------------- |
| 服务运行日志（挂载）                           | /tianrang-ocr/output/log/lpr.log      |
| 服务识别结果（需要配置file_record参数）        | /tianrang-ocr/output/result           |
| 本地json配置文件（若使用json文件进行参数配置） | /tianrang-ocr/flask_utils/config.json |



## 三、正确性验证

使用镜像内的脚本文件进行正确性验证。

修改以下命令中的`container id`：

`docker exec -it ${container id} /bin/bash -c "export LANG=C.UTF-8 LC_ALL=C.UTF-8;python /home/wjj/tianrang-ocr/flask_utils/test_req.py"`

验证返回值中的recognition字段是否一致：（部署不同的检测模型box字段会存在差异；部署不同的识别模型prob字段）

```json
{'data': [{'id': '2020-06-22T05:45:53_0', 'box': [[287, 729], [484, 729], [484, 792], [287, 792]], 'recognition': '赣B2371B', 'prob': 0.965}], 'code': 1, 'message': '', 'getImageTime': '2020-06-22T05:45:53'}
```



## 四、其他

由于本次镜像构建未用Dockerfile，因此在启动容器时需要设置中文及时区，预计在下个版本修复。

- 中文：`--env LANG=C.UTF-8 --env LC_ALL=C.UTF-8`
- 时区：`-v /etc/localtime:/etc/localtime:ro`



## 五、部署流程总结

- 1、准备部署镜像
- 2、将容器中`/tianrang-ocr/output`目录挂载出来
- 3、若使用json进行参数配置：将配置文件（`config.json`）挂载到容器内部`/tianrang-ocr/flask_utils/config.json`；若使用命令行进行参数配置：运行镜像时配置相应参数
- 4、设置环境变量支持中文、容器使用宿主机时区
- 5、部署正确性验证

